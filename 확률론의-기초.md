---


---

## 확률의 정의
확률을 정의하기 위해서는 우선 `표본공간`과 `사건공간`의 개념을 이해해야 한다. 

<br/>

### 표본공간 <span><script type="math/tex">\Omega</script></span>
[**표본공간**(Sample space)](https://en.wikipedia.org/wiki/Sample_space)이란 통계적 실험에서 발생할 수 있는 모든 결과들의 집합을 의미한다. 예를들어 동전 던지기의 표본(Sample)은 **H**(Head)와 **T**(Tail)이 될 수 있고, 표본공간은 다음과 같다. 

<div class="math"><script type="math/tex; mode=display">
\Omega = \{ \text{H}, \text{T} \}
</script></div>

<br/>

### 사건공간 <span><script type="math/tex">\mathcal{F}</script></span>
표본공간 <span><script type="math/tex">\Omega</script></span> 의 부분집합의 집합(Collection of subsets)인 <span><script type="math/tex">\mathcal{F} (\ne \phi)</script></span> 가 다음의 세 가지 조건을 만족할 때, <span><script type="math/tex">\mathcal{F}</script></span> 를 <span><script type="math/tex">\Omega</script></span> 의 **사건공간(Event space)** 이라고 한다. [시그마 대수(<span><script type="math/tex">\sigma</script></span>-algebra)](https://en.wikipedia.org/wiki/Sigma-algebra) 혹은 시그마 필드(<span><script type="math/tex">\sigma</script></span>-field) 라고도 부른다. 

1. <span><script type="math/tex">\phi \in \mathcal{F}</script></span>
2. <span><script type="math/tex">A \in \mathcal{F} \Longrightarrow A^c \in \mathcal{F}</script></span>
3. <span><script type="math/tex">A_i \in \mathcal{F} \Longrightarrow \bigcup_{i=1}^\infty A_i \in \mathcal{F}</script></span>

(1,2)번 조건으로 인해, 공집합 <span><script type="math/tex">\phi</script></span> 와 표본공간 <span><script type="math/tex">\Omega</script></span> 가 모두 <span><script type="math/tex">\mathcal{F}</script></span> 에 포함되어 있음을 알 수 있다. 그리고 (2,3)번 조건으로 인해, <span><script type="math/tex">\mathcal{F}</script></span> 가 모든 교집합과 합집합에 대해 닫혀있음을 알 수 있다. 

동전 던지기를 다시 예로 들어보면, 

<div class="math"><script type="math/tex; mode=display">
\mathcal{F} = \bigl\{  \phi, \{\text{H}\}, \{\text{T}\}, \Omega  \bigr\}
</script></div>

즉 <span><script type="math/tex">\mathcal{F}</script></span> 의 원소 하나하나가 [사건](https://en.wikipedia.org/wiki/Event_(probability_theory))에 해당한다는 사실을 알 수 있다. <span><script type="math/tex">\mathcal{F}</script></span> 를 사건공간이라고 부르는 이유가 된다. 

<br/>

### 확률 
확률이란, **사건 하나에 양의 실수값을 대응**시키는 함수를 의미한다. 좀 더 엄밀하게 정의해보자.  <span><script type="math/tex">(\Omega, \mathcal{F})</script></span>에 대해서, 어떤 함수 <span><script type="math/tex">\Pr(\cdot): \mathcal{F} \mapsto \mathbb{R}</script></span> 가 다음의 세 가지 조건을 만족할 때, <span><script type="math/tex">\Pr</script></span> 을 [확률측도(Probability measure)](https://en.wikipedia.org/wiki/Probability_measure) 또는 확률함수(Probability function) 라고 한다. 

1. <span><script type="math/tex">\Pr(C) \ge 0</script></span>, <span><script type="math/tex">~\forall C \in \mathcal{F}</script></span>
2. <span><script type="math/tex">\Pr(\Omega) = 1</script></span>
3. 서로소([disjoint](https://en.wikipedia.org/wiki/Disjoint_sets) 또는 [mutually exclusive](https://en.wikipedia.org/wiki/Mutual_exclusivity))인 사건들의 수열 <span><script type="math/tex">\{ C_1, C_2, \cdots  \mid C_i \in \mathcal{F}\}</script></span> 에 대해서, 
<div class="math"><script type="math/tex; mode=display">
\Pr \left( \bigcup_{i=1}^\infty C_i \right) = \sum_{i=1}^\infty \Pr(C_i)
</script></div>


여기서 이 세 가지 조건을 [Probability axioms](https://en.wikipedia.org/wiki/Probability_axioms) 또는 (Kolmogorov axioms, 콜모고로프 공리) 라고 부른다. 

동전 던지기의 각 사건에 대해, 위의 조건을 만족하는 확률함수를 다음과 같이 만들 수 있다. 
<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
\Pr(\phi) &= 0.0 \\
\Pr(\{ \text{H} \}) &= 0.5 \\
\Pr(\{ \text{T} \}) &= 0.5 \\
\Pr(\{ \Omega \}) &= 1.0
\end{aligned}
</script></div>

<br/>

### 확률의 주요성질
1. <span><script type="math/tex">\Pr(C) = 1 - \Pr(C^c)</script></span>
2. <span><script type="math/tex">\Pr(\phi) = 0</script></span>
3. <span><script type="math/tex">C_1 \subset C_2 \Longrightarrow \Pr(C_1) \le \Pr(C_2)</script></span>
4. <span><script type="math/tex">0 \le \Pr(C) \le 1</script></span>
5. <span><script type="math/tex">\Pr(C_1 \cup C_2)</script></span> <span><script type="math/tex">= \Pr(C_1) + \Pr(C_2) - \Pr(C_1 \cap C_2)</script></span>

위의 공리(Probability axioms)를 이용하면 모두 증명할 수 있다. 

**Proof.**

**1:**
<span><script type="math/tex">\Omega = C \cup C^c</script></span>, <span><script type="math/tex">~C \cap C^c = \phi</script></span> 이므로, 

<div class="math"><script type="math/tex; mode=display">
1 = \Pr(\Omega) = \Pr(C \cup C^c) = \Pr(C) + \Pr(C^c)
</script></div>

<br/>

**2:**
1번 증명에서 <span><script type="math/tex">C \overset{\text{let}}{=} \phi</script></span> 로 치환하면, 
<div class="math"><script type="math/tex; mode=display">
\Pr(\phi) = 1 - \Pr(\Omega) = 0
</script></div>

<br/>

**3:**
<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
C_2 
&= (C_1 \cup C_2) \cap \Omega \\
&= (C_1 \cup C_2) \cap (C_1 \cup C_1^c) \\
&= C_1 \cup (C_1^c \cap C_2)
\end{aligned}
</script></div>

이고, <span><script type="math/tex">C_1 \cap (C_1^c \cap C_2) = \phi</script></span> 이므로, 

<div class="math"><script type="math/tex; mode=display">
\Pr(C_2) = \Pr \left(C_1 \cup (C_1^c \cap C_2) \right) = \Pr(C_1) + \Pr(C_1^c \cap C_2)
</script></div>

여기서 <span><script type="math/tex">\Pr(C_1^c \cap C_2) \ge 0</script></span> 이므로, 증명이 완성된다. 

<br/>

**4:**
<span><script type="math/tex">\phi \subset C \subset \Omega</script></span> 이므로, 3번 성질에 의해

<div class="math"><script type="math/tex; mode=display">
0 = \Pr(\phi) \le \Pr(C) \le \Pr(\Omega) = 1
</script></div>

<br/>

**5:**
<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
C_1 \cup C_2 
&= (C_1 \cup C_2 ) \cap \Omega \\
&= (C_1 \cup C_2 ) \cap (C_1 \cup C_1^c) \\
&= C_1 \cup (C_1^c \cap C_2) \\[5pt]
C_2 
&= C_2 \cap \Omega \\
&= C_2 \cap (C_1 \cup C_1^c) \\
&= (C_1 \cap C_2) \cup (C_1^c \cap C_2)
\end{aligned}
</script></div>

이고, <span><script type="math/tex">C_1 \cap (C_1^c \cap C_2) = \phi</script></span>, <span><script type="math/tex">~(C_1 \cap C_2) \cap (C_1^c \cap C_2) = \phi</script></span> 임을 이용하면, 

<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
\Pr(C_1 \cup C_2) &= \Pr(C_1) + \Pr(C_1^c \cup C_2) \\
\Pr(C_2) &= \Pr(C_1 \cap C_2) + \Pr(C_1^c \cap C_2)
\end{aligned}
</script></div>

윗 식에서 아랫 식을 빼주면, 원하는 수식이 도출된다. 

<br/>

### 확률공간
이제까지 정의한 표본공간 <span><script type="math/tex">\Omega</script></span>, 사건공간 <span><script type="math/tex">\mathcal{F}</script></span>, 확률 <span><script type="math/tex">\Pr</script></span> 에 대해서, <span><script type="math/tex">(\Omega, \mathcal{F}, \Pr)</script></span> 을 [**확률공간**(Probability space)](https://en.wikipedia.org/wiki/Probability_space) 이라고 한다. 확률을 논하기 위해서는 언제나 이 3가지가 한 세트로 따라다닌다. 



<br/>

## 조건부 확률과 독립

### 결합확률
여러가지 사건이 동시에 발생할 확률을 결합확률이라고 한다. 


### 주변확률과 주변화


### 조건부 확률


### Law of total probability
### 독립사건

<br/>

## 확률변수

<br/>

## 확률분포
### 누적분포함수
### 확률밀도함수




<br/>

## 모멘트

### 기대값

<div class="math"><script type="math/tex; mode=display">
\mathbf{E} [X] = \sum_x x ~p(X=x)
</script></div>


* 단일 확률변수 함수인 경우:

<div class="math"><script type="math/tex; mode=display">
\mathbf{E} [g(X)] = \sum_x g(x) ~p(X=x)
</script></div>


* 다변수 확률변수 함수인 경우:

<div class="math"><script type="math/tex; mode=display">
\mathbf{E} [g(X, Y)] = \sum_{x, y} g(x, y) ~p(X=x, Y=y)
</script></div>

 

### 조건부 기대값
Conditional expected value

<div class="math"><script type="math/tex; mode=display">
\mathbf{E} [X \mid Y] = \sum_x x ~ p(X=x \mid Y)
</script></div>

### 분산과 표준편차


<br/>

## 독립항등분포
iid, independent and identically distributed


<br/>

## MECE

상호배제와 전체포괄(Mutually Exclusive & Collectively Exhaustive) 즉 서로 겹치지 않으면서 빠짐없이 나눈 것을 의미한다. 예를들어 어떤 집합 <span><script type="math/tex">A, ~B, ~C</script></span>가 다음을 만족할 때 MECE를 따른다고 할 수 있다. 

* <span><script type="math/tex">A \cap B = \phi</script></span>
* <span><script type="math/tex">A \cap C = \phi</script></span>
* <span><script type="math/tex">B \cap C = \phi</script></span>
* <span><script type="math/tex">A \cup B \cup C = U</script></span>



## Law of total expectation

Law of iterated expectation, Tower rule, Smoothing theorem, Adam's law 라도도 한다. 확률변수 <span><script type="math/tex">X</script></span>가 integrable (<span><script type="math/tex">\mathbf{E}[|X|] < \infty</script></span>) 할 때, 같은 확률공간에 있는 임의(integrable할 필요X)의 확률변수 <span><script type="math/tex">Y</script></span>에 대하여 다음이 성립한다. 

<div class="math"><script type="math/tex; mode=display">
\mathbf{E}[X] = \mathbf{E}[\mathbf{E}[X \mid Y]]
</script></div>


**Proof.**

<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
\mathbf{E} [\mathbf{E}[X \mid Y]]
&= \mathbf{E} \left[ \sum_x x \cdot \mathbf{P}(X=x \mid Y) \right] \\
&= \sum_y \left[ \sum_x x \cdot \mathbf{P}(X=x \mid Y=y) \right] \cdot \mathbf{P}(Y=y) \\
&= \sum_y \sum_x x \cdot \mathbf{P}(X=x \mid Y=y) \cdot \mathbf{P}(Y=y) \\
&= \sum_x x \sum_y \mathbf{P}(X=x, Y=y) \\
&= \sum_x x \cdot \mathbf{P}(X=x) \\
&= \mathbf{E}[X]
\end{aligned}
</script></div>


### Special cases

* <span><script type="math/tex">A_1, A_2, \cdots A_n</script></span>이 MECE 일때, 

<div class="math"><script type="math/tex; mode=display">
\mathbf{E}[X] = \sum_i \mathbf{E}[X \mid A_i] \mathbf{P}(\mathbf{E}[X \mid A_i]) = \sum_i \mathbf{E}[X \mid A_i] \mathbf{P}(A_i)
</script></div>


* <span><script type="math/tex">I_2 \subset I_1</script></span> 일때, 

<div class="math"><script type="math/tex; mode=display">
\mathbf{E}[X \mid I_1] = \mathbf{E}[\mathbf{E}[X \mid I_2] \mid I_1]
</script></div>

* Timeseries

<div class="math"><script type="math/tex; mode=display">
\mathbf{E}\_{t} [X] = \mathbf{E}\_{t} [\mathbf{E}\_{t+1}[X]]
</script></div>



## Law of total variance

Variance decomposition formula, Eve's law 라고도 한다. <span><script type="math/tex">X</script></span>와 <span><script type="math/tex">Y</script></span>가 같은 확률공간상의 확률변수이며 <span><script type="math/tex">Y</script></span>의 분산이 유한하다면, 다음이 성립한다. 

<div class="math"><script type="math/tex; mode=display">
\mathbf{Var}[Y] = \mathbf{E}[\mathbf{Var[Y \mid X]}] + \mathbf{Var}[\mathbf{E[Y \mid X]}]
</script></div>

<div class="math"><script type="math/tex; mode=display">
\text{분산 = 조건부 분산의 기대값 + 조건부 기대값의 분산}
</script></div>

* 앞부분 EVPV(Expected value of the process variance)
* 뒷부분 VHM(Variance of the hypothetical means)

특히 다음을 Law of total conditional variance라고 한다. 


<div class="math"><script type="math/tex; mode=display">
\mathbf{Var}[Y \mid X_1] = \mathbf{E}[\mathbf{Var[Y \mid X_1, X_2]} \mid X_1] + \mathbf{Var}[\mathbf{E[Y \mid X_1, X_2]} \mid X_1]
</script></div>


**Proof.**

<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
\mathbf{Var}[Y]
&= \mathbf{E}[Y^2] - \mathbf{E}[Y]^2 \\
&= \mathbf{E}[\mathbf{E}[Y^2 \mid X]] - \mathbf{E}[\mathbf{E}[Y \mid X]]^2  & \because \text{Law of total expectation} \\
&= \mathbf{E} \left[ \mathbf{Var}[Y \mid X] + \mathbf{E}[Y \mid X]^2 \right] - \mathbf{E}[\mathbf{E}[Y \mid X]]^2  & \because \mathbf{Var}[Y \mid X] = \mathbf{E}[Y^2 \mid X] - \mathbf{E}[Y \mid X]^2 \\
&= \mathbf{E} \left[ \mathbf{Var}[Y \mid X] \right] + \mathbf{E} \left[ \mathbf{E}[Y \mid X]^2 \right] - \mathbf{E}[\mathbf{E}[Y \mid X]]^2 \\
&= \mathbf{E} \left[ \mathbf{Var}[Y \mid X] \right] + \mathbf{Var}[\mathbf{E[Y \mid X]}]
\end{aligned}
</script></div>

