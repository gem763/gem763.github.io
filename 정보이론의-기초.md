---
layout: post
title: 정보이론의 기초
tags: [Probability theory]
categories: [Probability theory]
excerpt_separator: <!--more-->

---

## 정보
정보는 **갖고 싶을 만한 가치**를 지니고 있어야 한다. 마음만 먹으면 누구라도 가질 수 있거나, 너무 자주 발생해서 쉽게 알아낼 수 있다면, 그건 좋은 정보라고 말할 수 없다. 혹자는 정보를 **놀람의 크기**(Surprising degree) 또는 **파급력** 정도로 이해하기도 한다. 예를들어 어느 여름날 일기예보에서, `내일도 덥다`라고 말한다면, 정보로서의 가치가 크다고 말하기는 힘들다. 하지만 `올해 여름에는 눈이 내릴 가능성이 높다`라는 예보는 누가 듣더라도 엄청난 정보라고 얘기할 수 있을 것이다. 

[정보이론(Information theory)](https://en.wikipedia.org/wiki/Information_theory)에 따르면 정보량 <span><script type="math/tex">\mathbf{I}(\cdot): \mathbb{R} \mapsto \mathbb{R}</script></span> 은 발생확률 <span><script type="math/tex">p \in \mathbb{R}</script></span> 의 함수가 되며, 다음의 4가지 성질을 지니고 있다고 한다. 

1. 발생확률이 작을 수록 더 많은 정보량을 갖고 있다: 

<div class="math"><script type="math/tex; mode=display">
p_i \ge p_j \Longrightarrow \mathbf{I}(p_i) \le \mathbf{I}(p_j)
</script></div>

2. 정보량은 0 또는 양수이다:
<div class="math"><script type="math/tex; mode=display">
\mathbf{I}(p) \ge 0
</script></div>

3. 반드시 발생하는 사건(deterministic event)의 정보는 전혀 가치가 없다. 
<div class="math"><script type="math/tex; mode=display">\mathbf{I}(1) = 0</script></div>

4. 독립인 사건들의 정보량은 단순합산(additive)할 수 있다. 
<div class="math"><script type="math/tex; mode=display">
\mathbf{I}(p_i p_j) = \mathbf{I}(p_i) + \mathbf{I}(p_j)
</script></div>

여기서 정보량 <span><script type="math/tex">\mathbf{I}</script></span> 는 **self-information** 또는 **surprisal** 이라고도 부른다. 섀넌은 위의 성질들을 모두 만족하는 로그함수를 이용하여, 다음과 같이 정보량을 정의하였다. 

<div class="math"><script type="math/tex; mode=display">
\mathbf{I}(p) \equiv \log (1/p) = -\log p
</script></div>


정보이론에서는 기본 연산단위가 비트(bit)이기 때문에, 정보량의 정의에서 이진로그(<span><script type="math/tex">\log_2</script></span>)를 쓰는 경우가 많다. 이 때의 정보량 단위를  **비트**(bit) 또는 **섀넌**(shannon)이라고 한다. 예를들어 발생확률이 25%와 50%인 정보의 정보량을 각각 계산해보면, 

<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
\mathbf{I}(0.25) &= \mathbf{I}(2^{-2})= - \log_2 2^{-2} = 2 ~\text{bit} \\
\mathbf{I}(0.50) &= \mathbf{I}(2^{-1})= - \log_2 2^{-1} = 1 ~\text{bit}
\end{aligned}
</script></div>

즉 발생확률이 낮을 수록 정보량이 더 크다는 것을 알 수 있다. 참고로 **머신러닝**에서는 정보량의 정의에서 자연로그(<span><script type="math/tex">\ln</script></span>)를 쓰는 경우가 많은데, <span><script type="math/tex">\ln x</script></span>가 지수함수 <span><script type="math/tex">e^x</script></span>의 역함수일 뿐만 아니라 간편한 미분연산 등 대수적인 전개가 용이하기 때문이다.  이처럼 자연로그를 쓰는 경우의 정보량 단위를 **내트**(nat) 라고 한다. 정보량의 정의에 의해, <span><script type="math/tex">0 \le \mathbf{I}(p) \lt \infty</script></span> 임을 알 수 있다. 


<center><img src="https://gem763.github.io/assets/img/20180723/info_shape.PNG" alt="info_shape"/></center>

<br/>

## 엔트로피

[**엔트로피**(Entropy)](https://en.wikipedia.org/wiki/Entropy_(information_theory))는 **확률변수의 불확실성(Uncertainty)을 측정**하는 도구 중의 하나이다. 원래는 고전 열역학에서 소개된 개념인데, 섀넌의 1948년 논문인 [A Mathematical Theory of Communication](https://en.wikipedia.org/wiki/A_Mathematical_Theory_of_Communication)을 통해 정보이론으로 접목되었다. 확률변수 <span><script type="math/tex">X</script></span>와 확률밀도함수 <span><script type="math/tex">p</script></span> 에 대해서, **엔트로피** <span><script type="math/tex">\mathbf{H} \in \mathbb{R}</script></span>는 **정보량** <span><script type="math/tex">\mathbf{I}</script></span> **의 기대값**으로 정의된다. 

<div class="math"><script type="math/tex; mode=display">
\mathbf{H}(X) \equiv  \mathbf{E}_{p(X)} [\mathbf{I}(p(X))] = -\mathbf{E}_{p(X)}[\log p(X)]
</script></div>

여기서 연산자 <span><script type="math/tex">\mathbf{E}_{p(X)}[\cdot]</script></span> 는 확률밀도함수 <span><script type="math/tex">p</script></span> 대한 기대값을 의미한다. 엔트로피의 단위는 정보량의 단위에 따라 달라진다. [^unit_entropy]

[^unit_entropy]: 만약 정보량의 단위가 비트라면(즉 정보량을 이진로그로 정의한다면) 엔트로피의 단위도 비트가 된다. 반대로 정보량의 단위가 내트라면(즉 정보량을 자연로그로 정의한다면) 엔트로피의 단위 역시 내트가 된다. 

엔트로피는 **정보의 불확실성**이나, 해당 정보를 접했을 때 느끼는 **평균적인 파급력(놀람)의 크기** 정도로 해석한다. 왜냐하면 다음과 같은 추론이 가능하기 때문이다. 

1. 정보량의 기대값이 크면, 
2. 해당 정보에 대한 평균적인 파급력의 크기가 클 것이고, 
3. 이느 결과적으로 해당 정보의 불확실성이 크다는 것을 의미한다. 

만약 확률변수 <span><script type="math/tex">X</script></span>가 [베르누이 분포](https://gem763.github.io/probability%20theory/%EB%B2%A0%EB%A5%B4%EB%88%84%EC%9D%B4-%EB%B6%84%ED%8F%AC%EC%99%80-%EC%9D%B4%ED%95%AD%EB%B6%84%ED%8F%AC.html) 또는 [카테고리 분포](https://gem763.github.io/probability%20theory/%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC-%EB%B6%84%ED%8F%AC%EC%99%80-%EB%8B%A4%ED%95%AD%EB%B6%84%ED%8F%AC.html) 등의 **이산확률분포**를 따른다면, 엔트로피를 좀 더 명시적으로 나타낼 수 있다. 이를 **섀넌 엔트로피**(Shannon entropy) 또는 **정보 엔트로피**(Information entropy) 라고 부르기도 한다.[^info_entropy] 이산확률변수 <span><script type="math/tex">X</script></span>가 취할 수 있는 모든 값의 범위 <span><script type="math/tex">\mathbb{X}</script></span> [^sample_space] 대하여, 

[^info_entropy]: 이와는 반대 개념으로, 연속확률변수에 대한 엔트로피를 [연속 엔트로피(Continuous entropy or Differential entropy)](https://en.wikipedia.org/wiki/Entropy_(information_theory)#Extending_discrete_entropy_to_the_continuous_case) 라고 한다. 연속확률변수 <span><script type="math/tex">X</script></span>가 가질 수 있는 모든 값의 범위를 <span><script type="math/tex">\mathbb{X}</script></span> 라고 한다면, 연속 엔트로피는 다음과 같이 정의된다. <div class="math"><script type="math/tex; mode=display">\mathbf{H}(X) = -\int_\mathbb{X} p(X) \log p(X) ~dx</script></div>

[^sample_space]: 표본공간 (Sample space) 라고 부른다. 

<div class="math"><script type="math/tex; mode=display">
\mathbf{H}(X) = -\sum_{x \in \mathbb{X}} p(x) \log p(x)
</script></div>

이 경우 <span><script type="math/tex">p(\cdot)</script></span> 는 확률질량함수가 된다. 한편 이산확률변수 <span><script type="math/tex">X</script></span>에서 나온 <span><script type="math/tex">n</script></span>개의 샘플 데이터 <span><script type="math/tex">(x_1, \cdots, x_n)</script></span>와 각 샘플 <span><script type="math/tex">x_i</script></span>에 할당된 확률값 <span><script type="math/tex">p_i \equiv p(x_i)</script></span> 에 대해서, 엔트로피를 다음과 같이 표현하기도 한다. 

<div class="math"><script type="math/tex; mode=display">
\mathbf{H}(X) = \mathbf{H}_n (p_1, \cdots, p_n) = - \sum_i p_i \log p_i
</script></div>

<br/>

> <big><b><span><script type="math/tex">p = 0</script></span> 인 경우</b></big>
> 
> 이산확률변수 <span><script type="math/tex">X</script></span>에서 추출된 어떤 샘플의 발생확률이 <span><script type="math/tex">p=0</script></span> 일 때에는 해당 엔트로피의 계산에 <span><script type="math/tex">0 \log 0</script></span> 이 포함되기 때문에, 엔트로피가 정의되지 않는다. 이 경우에는 
> <div class="math"><script type="math/tex; mode=display">\Bigl[ p \log p \Bigr]_{p = 0} \equiv \lim_{p \to 0+} p \log p</script></div>
>를 이용한다.  [로피탈의 정리(L'Hospital's rule)](https://en.wikipedia.org/wiki/L%27H%C3%B4pital%27s_rule)에 의해, 
><div class="math"><script type="math/tex; mode=display">\lim_{p \to 0+} p \log p = \lim_{p \to 0+} \frac{(\log p)'}{(1/p)'} = \lim_{p \to 0+} \frac{1/p}{-1/p^2} = 0</script></div>
>이므로, 발생확률이 0인 정보량은 엔트로피 계산에서 제외해도 상관없게 된다. 따라서 발생확률이 0이 아닌 샘플들의 집합 <span><script type="math/tex">\mathbb{X}_o</script></span> <span><script type="math/tex">(\subset \mathbb{X})</script></span>에 대해서, 엔트로피는 다음과 같이 계산된다. 
><div class="math"><script type="math/tex; mode=display">\mathbf{H}(X) = -\sum_{x \in \mathbb{X}_o} p(x) \log p(x)</script></div>
>



<br/>

### 사례: 동전 던지기
동전 던지기를 통해 엔트로피의 개념을 이해해보자. 동전 던지기의 확률변수 <span><script type="math/tex">X \in \{ 0, 1 \}</script></span>는 성공확률 <span><script type="math/tex">\theta \equiv p(X=1) \in \mathbb{R}</script></span> 의 [베르누이 분포](https://gem763.github.io/probability%20theory/%EB%B2%A0%EB%A5%B4%EB%88%84%EC%9D%B4-%EB%B6%84%ED%8F%AC%EC%99%80-%EC%9D%B4%ED%95%AD%EB%B6%84%ED%8F%AC.html#%EB%B2%A0%EB%A5%B4%EB%88%84%EC%9D%B4-%EB%B6%84%ED%8F%AC)를 따른다. 자연로그를 이용하여 엔트로피를 산출해보자. 

<div class="math"><script type="math/tex; mode=display">
X \sim \mathbf{Bern}(\theta)
</script></div>

<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
\mathbf{H}(X) &= -p(1) \ln p(1) - p(0) \ln p(0)\\
&= -\theta \ln \theta - (1-\theta) \ln (1-\theta)
\end{aligned}
</script></div>

이처럼, 베르누이 분포의 엔트로피를 성공확률 <span><script type="math/tex">\theta</script></span>의 함수로 나타내는 것을 [이진 엔트로피 함수 (Binary entropy function)](https://en.wikipedia.org/wiki/Binary_entropy_function) 라고 부른다. [^bin_entropy]

[^bin_entropy]: 보통은 이진로그로 정의하는 경우가 많으나, 여기에서는 자연로그를 썼다. 


* <span><script type="math/tex">\theta=0</script></span> 인 경우: 
<div class="math"><script type="math/tex; mode=display">\mathbf{H}(X ; \theta=0) = -0 \ln 0 - 1 \ln 1 = 0</script></div>

* <span><script type="math/tex">\theta=0.3</script></span> 인 경우: 
<div class="math"><script type="math/tex; mode=display">\mathbf{H}(X ; \theta=0.3) = -0.3 \ln 0.3 - 0.7 \ln 0.7 \approx 0.61</script></div>

* <span><script type="math/tex">\theta=0.5</script></span> 인 경우: 
<div class="math"><script type="math/tex; mode=display">\mathbf{H}(X ; \theta=0.5) = -0.5 \ln 0.5 - 0.5 \ln 0.5 \approx 0.69</script></div>

<span><script type="math/tex">\theta=0.5</script></span> 에 가까울 수록 엔트로피가 커진다는 사실을 알 수 있다. 이는 **공정(fair)한 동전일 수록 불확실성이 커진다**는 것을 의미한다. 0과 1 사이의 모든 <span><script type="math/tex">\theta</script></span>에 대해서 엔트로피를 그려보면 다음 차트를 얻게된다. 

<center><img src="https://gem763.github.io/assets/img/20180723/entropy_bern.PNG" alt="entropy_bern"/></center>

<br/>


### 주요성질




* 확률변수 <span><script type="math/tex">X</script></span>가 [이산균등분포(Discrete uniform distribution)](https://en.wikipedia.org/wiki/Discrete_uniform_distribution)를 따르고, 샘플이 <span><script type="math/tex">n</script></span>개의 서로 다른 값들로 구성되어 있다고 하자. 각 샘플의 확률값을 <span><script type="math/tex">p_i</script></span> 라고 할 때, <span><script type="math/tex">p_i=\frac{1}{n}</script></span> 이므로
<div class="math"><script type="math/tex; mode=display">
\mathbf{H}(X) = \mathbf{H}_n (\tfrac{1}{n}, \cdots, \tfrac{1}{n}) = - \sum_i p_i \ln p_i = \ln n
</script></div>

* 확률변수 <span><script type="math/tex">Y</script></span> 역시 이산균등분포를 따르고, <span><script type="math/tex">m</script></span>개의 서로 다른 값들로 구성되어 있으며, 각 샘플의 확률값이 <span><script type="math/tex">q_j</script></span> 라고 하면, <span><script type="math/tex">q_j = \frac{1}{m}</script></span> 이 된다. 위의 <span><script type="math/tex">X</script></span>와 <span><script type="math/tex">Y</script></span>가 서로 독립이라고 가정하면, 결합확률 <span><script type="math/tex">(X,Y)</script></span> 의 확률질량함수는 <span><script type="math/tex">p_i q_j = \frac{1}{nm}</script></span> 이 되므로
<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
\mathbf{H}(X,Y) 
&= \mathbf{H}_{nm}(\tfrac{1}{nm}, \cdots, \tfrac{1}{nm}) \\
&= -\sum_{i,j} p_i q_j \ln (p_i q_j) \\
&= \ln nm \\
&= \ln n + \ln m
\end{aligned}
</script></div>
즉 이산균등분포를 따르고 독립인 확률변수의 엔트로피는, 각 확률변수의 엔트로피의 합과 같다. 이는, **독립적인 불확실성은 가산된다**는 의미로 해석된다. 

<br/>

## 결합 엔트로피
[**결합 엔트로피** (Joint entropy)](https://en.wikipedia.org/wiki/Information_theory#Joint_entropy)는 [결합확률분포 (Joint probability distribution)](https://en.wikipedia.org/wiki/Joint_probability_distribution)의 엔트로피를 말한다. 
두 확률변수 <span><script type="math/tex">X</script></span>, <span><script type="math/tex">Y</script></span>에 대해 결합확률변수 <span><script type="math/tex">(X,Y)</script></span>의 확률밀도함수를 <span><script type="math/tex">p(X,Y)</script></span>라고 한다면, 결합 엔트로피는 다음과 같이 정의된다. 

<div class="math"><script type="math/tex; mode=display">
\mathbf{H}(X,Y) \equiv -\mathbf{E}_{p(X,Y)} [\log p(X,Y)]
</script></div>

확장하여, 결합확률변수 <span><script type="math/tex">\mathbf{X} = (X_1, \cdots, X_n)</script></span>의 확률밀도함수를 <span><script type="math/tex">p(\mathbf{X})</script></span> 라고 하면, 

<div class="math"><script type="math/tex; mode=display">
\mathbf{H}(\mathbf{X}) \equiv -\mathbf{E}_{p(\mathbf{X})} [\log p(\mathbf{X})]
</script></div>

가 된다. 만약 각 확률변수 <span><script type="math/tex">X_i</script></span>가 이산확률분포를 따른다면, 결합확률변수 <span><script type="math/tex">\mathbf{X}</script></span>의 샘플 <span><script type="math/tex">\mathbf{x}</script></span>가 취할 수 있는 모든 값에 대하여, 

<div class="math"><script type="math/tex; mode=display">
\mathbf{H}(\mathbf{X}) = - \sum_{\mathbf{x}} p(\mathbf{x}) \log p(\mathbf{x})
</script></div>

<br/>

## 교차 엔트로피
확률변수 <span><script type="math/tex">X</script></span>에 두 개의 확률분포 <span><script type="math/tex">p</script></span> 와 <span><script type="math/tex">q</script></span> 가 있다고 생각해보자. 현실에서는 이런 경우가 빈번하다. 이를테면 **확률변수 <span><script type="math/tex">X</script></span>의 분포를 모르고 있는 상태**에서 확률밀도함수를 추정한다면, 해당 확률밀도함수의 형태는 여러가지가 될 수 있는 것이다. 이럴 때에는 다음과 같이 [**교차 엔트로피** (Cross entropy)](https://en.wikipedia.org/wiki/Cross_entropy) <span><script type="math/tex">\mathbf{H}_{p,q}</script></span> 를 정의할 수 있다. 

<div class="math"><script type="math/tex; mode=display">
\mathbf{H}_{p,q}(X) \equiv - \mathbf{E}_{p(X)} [\log q(X)]
</script></div>

로그 안과 밖의 확률밀도함수가 다르다는 점만 제외하고는, 기존의 엔트로피 정의와 동일하다. 만약 확률변수 <span><script type="math/tex">X</script></span>가 이산확률분포를 따른다면, <span><script type="math/tex">X</script></span>가 취할 수 있는 모든 값의 범위 <span><script type="math/tex">\mathbb{X}</script></span>에 대해 다음과 같이 나타낼 수 있다. 

<div class="math"><script type="math/tex; mode=display">
\mathbf{H}_{p,q}(X) = - \sum_{x \in \mathbb{X}} p(x) \log q(x)
</script></div>

베르누이 분포를 예로 들어보자. 확률변수 <span><script type="math/tex">X</script></span>의 세 확률분포 <span><script type="math/tex">p</script></span>, <span><script type="math/tex">q_1</script></span>, <span><script type="math/tex">q_2</script></span>에 대한 성공확률 <span><script type="math/tex">\theta</script></span>를 

<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
\theta_p &\equiv p(X=1) = 0.2 \\
\theta_{q_1} &\equiv q_1(X=1) = 0.3 \\
\theta_{q_2} &\equiv q_2(X=1) = 0.9
\end{aligned}
</script></div>

라고 한다면, 

<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
\mathbf{H}_{p,q_1}(X) &= -\theta_{p} \ln \theta_{q_1} - (1-\theta_{p}) \ln (1-\theta_{q_1}) \\
&= - (0.2 \times \ln 0.3) - (0.8 \times \ln 0.7) \\
&= 0.526
\end{aligned}
</script></div>

<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
\mathbf{H}_{p,q_2}(X) &= -\theta_{p} \ln \theta_{q_2} - (1-\theta_{p}) \ln (1-\theta_{q_2}) \\
&= - (0.2 \times \ln 0.9) - (0.8 \times \ln 0.1) \\
&= 1.863
\end{aligned}
</script></div>

**두 확률분포가 유사할 수록 교차 엔트로피가 작아진다**는 사실을 알 수 있다. 베르누이 분포에서 0과 1 사이의 모든 성공확률 <span><script type="math/tex">\theta_p</script></span>, <span><script type="math/tex">\theta_q</script></span>에 대한 교차 엔트로피를 그려보면 다음 차트를 얻게된다. 두 확률분포가 유사한 구간인 <span><script type="math/tex">\theta_p \approx \theta_q</script></span> (점선) 부근에서 교차 엔트로피가 0에 가깝다는 것을 다시한번 확인할 수 있다. 

<center><img src="https://gem763.github.io/assets/img/20180723/cross_entropy.PNG" alt="cross_entropy"/></center>

이와 같은 성질 때문에, 교차 엔트로피는 머신러닝의 [분류 (Classification)](https://en.wikipedia.org/wiki/Statistical_classification) 문제에서 [비용함수 (Cost function)](https://en.wikipedia.org/wiki/Loss_function)으로 쓰이는 경우가 많다. 위의 예를 다시한번 가져와 보자. <span><script type="math/tex">p</script></span>를 <span><script type="math/tex">X</script></span>의 실제 확률분포라고 하고, 해당 확률분포를 추정하여 <span><script type="math/tex">q_1</script></span>과 <span><script type="math/tex">q_2</script></span>를 얻게 되었다고 하자. 각 성공확률값에 따라 [One-hot 인코딩](https://en.wikipedia.org/wiki/One-hot)을 통해 클래스를 분류해보면, 


<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
p : (0.2, 0.8) &\xrightarrow{\text{One-hot }} p': (0, 1) = \color{red}{\text{class 2}}\\
q_1 : (0.3, 0.7) &\xrightarrow{\phantom{\text{One-hot }}} q_1': (0, 1) = \text{class 2}\\
q_2 : (0.9, 0.1) &\xrightarrow{\phantom{\text{One-hot }}} q_2': (1, 0) = \text{class 1}
\end{aligned}
</script></div>

<span><script type="math/tex">p</script></span>가 실제 분포라고 했으므로, 이 확률변수를 분류해보면 **class 2**가 틀림없다. 이제, 추정된 분포 <span><script type="math/tex">q_1</script></span>과 <span><script type="math/tex">q_2</script></span>를 통해 인코딩된 분류를, 교차 엔트로피를 이용하여 검증해보자. 

<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
\mathbf{H}_{p',q_1'}(X) &= -0 \ln 0 - 1 \ln 1 = 0 \\
\mathbf{H}_{p',q_2'}(X) &= -0 \ln 1 - 1 \ln 0 = \infty \\
\end{aligned}
</script></div>

즉, 잘못된 분류를 도출하는 분포의 경우에는 교차 엔트로피가 무한대로 발산하게 된다. 


<br/>

## 조건부 엔트로피
확률변수 <span><script type="math/tex">X</script></span>의 값을 조건으로 확률변수 <span><script type="math/tex">Y</script></span>의 조건부 확률을 구할 수 있다. 마찬가지로 확률변수 <span><script type="math/tex">X</script></span>의 값을 조건으로 확률변수 <span><script type="math/tex">Y</script></span>의 엔트로피를 산출할 수 있는데, 이를 [**조건부 엔트로피** (Conditional entropy)](https://en.wikipedia.org/wiki/Conditional_entropy) [^cond_entropy]라고 한다. 확률변수 <span><script type="math/tex">Y</script></span>에 관한 엔트로피의 <span><script type="math/tex">X</script></span>에 대한 기대값으로 정의한다. 

[^cond_entropy]: 조건부 불확실성 또는 Equivocation 라고도 부른다. 

<div class="math"><script type="math/tex; mode=display">
\mathbf{H}(Y \mid X) 
\equiv \mathbf{E}_{p(X)} \bigl[ \mathbf{H}(Y \mid X=x) \bigr]
</script></div>

만약 확률변수 <span><script type="math/tex">X</script></span>, <span><script type="math/tex">Y</script></span>가 이산확률분포를 따른다면, [조건부 확률](https://en.wikipedia.org/wiki/Conditional_probability) 및 엔트로피의 정의에 의해 다음과 같이 전개할 수 있다. 

<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
\mathbf{H}(Y \mid X) 
&= \sum_x p(x) ~\mathbf{H}(Y \mid x) \\
&= -\sum_x p(x) ~\sum_y p(y \mid x) \log p(y \mid x)\\
&= -\sum_{x,y} p(x) ~p(y \mid x) \log p(y \mid x)\\
&= -\sum_{x,y} p(x,y)  \log p(y \mid x)
\end{aligned}
</script></div>

결합 엔트로피 <span><script type="math/tex">\mathbf{H}(X,Y)</script></span> <span><script type="math/tex">= -\mathbf{E}_{p(X,Y)} [\log p(X,Y)]</script></span> <span><script type="math/tex">= -\sum_{x,y} p(x,y)  \log p(x,y)</script></span> 와 헷갈릴 수 있으니, 주의하기 바란다. 

<br/>

### Chain rule
조건부 엔트로피는 다음과 같은 재미있는 성질이 있는데, 이를 Chain rule 이라고 부른다. 

<div class="math"><script type="math/tex; mode=display">
\mathbf{H}(Y \mid X) = \mathbf{H}(X,Y) - \mathbf{H}(X)
</script></div>

증명해보자. 

<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
\mathbf{H}(Y \mid X) 
&= -\sum_{x,y} p(x,y)  \log p(y \mid x) \\
&= -\sum_{x,y} p(x,y)  \log \frac{p(x,y)}{p(x)} \\
&= -\sum_{x,y} p(x,y) \log p(x,y) + \sum_{x,y} p(x,y) \log p(x) \\
&= \mathbf{H}(X,Y) + \sum_x \left( \sum_y p(x,y) \right) \log p(x)
\end{aligned}
</script></div>

여기서 

<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
-\sum_{x,y} p(x,y) \log p(x,y) &= \mathbf{H}(X,Y) \\
\sum_{x,y} p(x,y) \log p(x) &= \sum_x \left( \sum_y p(x,y) \right) \log p(x) \\
&= \sum_x p(x) \log p(x) \\
&= -\mathbf{H}(X)
\end{aligned}
</script></div>

임을 이용하면 증명이 완성된다. 보다 일반적인 형태로는 다음과 같이 쓸 수 있다. 

<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
\mathbf{H}(X_1, \cdots, X_n) 
&= \sum_{i=1}^n \mathbf{H}(X_i \mid X_1, \cdots, X_{i-1}) 
\end{aligned}
</script></div>

증명은 간단하다. 다음 식들을 모두 합산해보면 위의 식을 얻게 된다.  

<div class="math"><script type="math/tex; mode=display">
\begin{aligned}
\mathbf{H}(X_n \mid X_1, \cdots, X_{n-1}) &= \mathbf{H}(X_1, \cdots, X_n) - \mathbf{H}(X_1, \cdots, X_{n-1}) \\
\mathbf{H}(X_{n-1} \mid X_1, \cdots, X_{n-2}) &= \mathbf{H}(X_1, \cdots, X_{n-1}) - \mathbf{H}(X_1, \cdots, X_{n-2}) \\
&\cdots \\
\mathbf{H}(X_{2} \mid X_1) &= \mathbf{H}(X_1, X_{2}) - \mathbf{H}(X_1) \\
\mathbf{H}(X_{1}) &= \mathbf{H}(X_1) \\
\end{aligned}
</script></div>

<br/>




### 정보이득

정보이득(Information Gain, 이하 IG)는 확률변수의 불확실성이 얼마나 감소했는지를 나타내는 지표이다. 다음과 같이 정의된다. 

<div class="math"><script type="math/tex; mode=display">
IG(Y, X) \equiv \mathcal{H}(Y) - \mathcal{H}(Y \mid X)
</script></div>



<br/>

## KL 다이버전스

KL 다이버전스(Kullback-Leiber divergence)는 두 확률분포 간의 차이를 측정하는 도구이다. 확률분포 <span><script type="math/tex">q</script></span>와 <span><script type="math/tex">p</script></span>에 대하여  

<div class="math"><script type="math/tex; mode=display">
D_{KL} (q \parallel p) \equiv \sum_i q(i) \ln \frac{q(i)}{p(i)}
</script></div>

로 정의되며, 다음의 성질을 지닌다. 

* 두 분포가 유사할 수록 KL 다이버전스가 작으며, <span><script type="math/tex">q = p</script></span>인 경우 <span><script type="math/tex">D_{KL} (q \parallel p) = 0</script></span> 이다.
* <span><script type="math/tex">D_{KL} (q \parallel p) \ne D_{KL} (p \parallel q)</script></span>
* <span><script type="math/tex">D_{KL} (q \parallel p) \ge 0</script></span>


위의 성질 중 <span><script type="math/tex">D_{KL} (q \parallel p) \ge 0</script></span> 은 Jensen 부등식을 이용하여 증명할 수 있다. 

<div class="math"><script type="math/tex; mode=display">
D_{KL} (q \parallel p) = - \sum_i q_i \ln \frac{p_i}{q_i} \ge - \ln \left[ \sum_i q_i \frac{p_i}{q_i} \right] = - \ln \left[ \sum_i p_i \right] = 0
</script></div>


## Jesen 부등식

함수 <span><script type="math/tex">\phi</script></span>가 convex하고, 확률변수 <span><script type="math/tex">X</script></span>에 대하여 <span><script type="math/tex">\operatorname{E}(X)</script></span>가 유한할 때, 다음이 성립한다. 

<div class="math"><script type="math/tex; mode=display">
\phi [\operatorname{E}(X)] \le \operatorname{E}[\phi (X)]
</script></div>

만약 <span><script type="math/tex">\phi</script></span>가 strictly convex 인 경우, strict inequality가 적용된다. 


| <span><script type="math/tex">\phi(\cdot)</script></span>의 형태 | 부등식 |
| -------- | -------- |
| convex (아래로 볼록) | <span><script type="math/tex">\displaystyle \phi \left( \frac{\sum a_i x_i}{\sum a_j} \right) \le \frac{\sum a_i \phi(x_i)}{\sum a_j}</script></span> |
| concave (위로 볼록) | <span><script type="math/tex">\displaystyle \phi \left( \frac{\sum a_i x_i}{\sum a_j} \right) \ge \frac{\sum a_i \phi(x_i)}{\sum a_j}</script></span> |


